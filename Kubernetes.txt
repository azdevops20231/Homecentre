Kubernetes 
---------------------


Master
Worker Nodes  -vm
Pods
Containers


master is responsible for managing the cluster
In each worker node we have pods and each pod can contains n number of containers in it.
for example if a worker node fails it moves the workload to the other healthy nodes


Master:
---------
4 components

1)API server :its a gatekeeper for entire cluster,it manges and creates ,delete inside a kubclster it needs to paas through apiserver

2)scheduler:physically scheduling pods across multiple nodesdepending upon constraints u mention in the 
configuaration files ,scheduler schedules pods accordingly


example :if you pass your artifact to the api server the scheduler will look for the requiremennt
  requires some few resources like cpu ,vcore,ssd it will be taken care by the controller 


3)Control manager: 4 types 1)node controller 2)replication controller 3)endpoint controller  4) service account and token controller 

these controllers are responsible for overall health of your cluster,it makes sures that all the nodes are up and running and maintains 
the correct number of pods are running as mentioned in the spec files

4)ETCD:its a keyvalue light wight database to store current cluster state,anypoint of time any component in the cluster can communicate
with etcd to the state of the cluster.etcd is a database which stores nodes,secrets .


Worker nodes:

---------------------


these are nothing but physical nodes or vm's where your containers are deployed

every node in the cluster run a container runtime such as docker 
in the worker node there are 2 other components we have to communicate with master node 

 1)Kubelet:its a primary node agent that is installed on the worker node ,the primary objective of this kubelet is that it
looks for pod spec that is submitted on the api server, and ensures that containers in the node are running and healthy.

-->incase if the kubelet notices any of the pods are unhealthy , then it tries to restart the  pod on the same worker node

---> if it is a problem with the worker node itself master detects the failure and then master decides to recreate the pod
on another healthy worker node ,,so it all dependes on replicaset or replica controller ,if none of them configured the pod
dies and would not be recreated,so it is advised for a pod to use deployment or a replica set.




2)KubeProxy: it is responsible for maintaning the entire network configuaration


Pods:it is nothing but a scheduling unit in kubernetes ,just like vm  in a vmware,each pod can have one or more containers inside it.


primary advantage of pod is we can deploy multiple containers in a pod which are dependent containers together


containers: it is nothing but provides runtime environment for ur applciation,you can run applications inside these containers.containers can contains libraries ,dependencies and applications



For Practice you can try these 
------------------------------------:

play with k8s

minikube :it doesnot have separate set up like master and the worker node ,it can be installed on machines with less requirement of cpu and ram

kubeadm :popular , u can crete multiple vm's in any cloud provider and can create master and worker nodes to get realtime experience


Cloud Providers which offer kubernetes 

GKE ---google kubernetes engine
AKS----azure kubernetes service
amazon EKS---elastic kubernetes service


Kubectl : to interact with kubernetes cluster we can use kubectl command line utility

commands:

kubectl get pods podname
kubectl get services
kubectl get deployments
kubectl get ingress
kubectl describe pod podname
kubectl describe svc svcname
kubectl delete -f yamlfile
kubectl delete svc svcname
kubectl delete deployment deploymentname
kubectl exec -it podname /bin/bash
kubectl logs --logs for a container


Kubernetes

 what is a Services: each pod in kubernetes assigned with an ip address, when a pod gets recreated a new ip will be assigned to that ,so you need to update that each time pod gets new IP.
But when u use service it will be containg stable ip address it stays same even when pod dies. and service also provides load balancing  


Kinds of Services:
 1)cluster IP :used mostly and its default type , as a example consider this a pod can have 2 containers running in it ,one container listens on port 3000,and other contianer listens on port 8000
those 2 pods are accessible now and run inside the pod, each pod can have an IP from a range i,e assigned to nodes , lets consider we have 3 nodes and each node will get range of IP Address range

node1:10.2.0.0 --pod ---ipaddress
node2:10.2.1.0
node3:10.2.2.0---10.2.2.4

If you want to get the pod IP addresses u can use kubectl get pod -o wide


Now lets consider we have made an replica set as 1 , so if pod goes down immediately kubernetes will create new pod with the containers running in it .

example:


we have 2 nodes , and in these 2 nodes we have pods and inside the pod we have cointainers running in it ,so how does the users can interact with your application?consider these microservices
are acceesible from browser, so the requests from the browser to the microservices will be handled by ingress controller, and how this ingress  forwards the requests to pod?
this is done with the help of a service , a service wil be containing an Ip address which can accessible on defined port number , and service will know to which pod it needs to send requests to and which port?
so in the  service you need to mention "selector" as your podname...labels are nothing but key value pairs ,so when you want to select any pod you need to mention the labels .

how does service know which pod and port to forward the request?
this can be done using target port 


2)nodeport service: type node port creates a service that is accessible on a static port on each worker node in the cluster, if we compare cluster ip and node port ,cluster will be accessible within cluster
nodeport makes external traffic has access to fixed port on each worker node, instead on ingress browser requests comes directly to nodeport.nodeport services are not secure


3)loab balancer services:service becomes accessbile externally through a cloud provider LB functionality ,whenever we create load balancer nodeport and clusterip services
are created automatically

type : load balancer


Ingress :  when any requests from browser will first hit the ingress and then it goes to internal serviceand then it goes to pod

in ingress we write routing rules 

example : kind ingress ,here you specify rules in the yaml file ,so when any requests comes to the Host www.google.com ,it must be forwarded to any internal service.

the best practice was first your request will hit the load balancer and load balancer sends the request to ingress controller.

























